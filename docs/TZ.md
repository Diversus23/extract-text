# Техническое задание: API для извлечения текста для RAG

**Версия:** 1.10.4
**Дата:** 29.07.2025

---

### 1. Общие сведения

**1.1. Назначение системы:**
Разработка серверного API (далее — Сервис) для комплексного извлечения текстового содержимого из файлов различных форматов. Сервис предназначен для развертывания в корпоративной сети предприятия.

**1.2. Конечная цель и контекст использования:**
Извлеченный текст будет использоваться для создания векторных представлений (embeddings) с последующей загрузкой в векторную базу данных в рамках системы **RAG (Retrieval-Augmented Generation)**.
Ключевыми приоритетами являются **полнота, точность и структурированность** извлекаемых данных для обеспечения максимального качества работы RAG-модели.

### 2. Термины и определения

* **RAG (Retrieval-Augmented Generation):** Архитектура, объединяющая языковые модели с внешними базами знаний для повышения точности и релевантности ответов.
* **OCR (Optical Character Recognition):** Оптическое распознавание символов; технология преобразования изображений с текстом в машиночитаемый текст.
* **API (Application Programming Interface):** Программный интерфейс приложения.

### 3. Функциональные требования

**3.1. Общая стратегия извлечения:**
Сервис должен извлекать **весь доступный текстовый контент** из файла, объединяя данные из разных источников (текстовый слой, OCR, метаданные) в единый вывод.

**3.2. Обработка PDF-документов:**
1. Извлекается основной текстовый слой документа.
2. Из документа извлекаются все встроенные изображения.
3. К каждому изображению применяется процедура OCR (согласно п. 3.4).
4. Текст, полученный после OCR, объединяется с текстом из основного слоя.  Рекомендуемая структура итогового текста для сохранения семантической связности:

```
[Текст со страницы 1]
[Текст с первого изображения на странице 1]
[Текст со второго изображения на странице 1]
[Текст со страницы 2]
...
```

**3.3. Обработка документов (`.doc`, `.docx`, `.odt`, `.rtf`) и презентаций (`.pptx`, `.ppt`):**
* Извлекается текст из основного тела документа, а также из **колонтитулов, сносок, комментариев и заметок спикера**.
* К встроенным изображениям применяется процедура OCR.
* Для `.doc` файлов (старый формат Microsoft Word) используется конвертация в `.docx` через LibreOffice в headless режиме для максимальной совместимости.
* Для `.ppt` файлов (старый формат Microsoft PowerPoint) используется конвертация в `.pptx` через LibreOffice в headless режиме для максимальной совместимости.

**3.4. Обработка изображений и OCR:**
* **Поддерживаемые форматы:** `.jpg`, `.jpeg`, `.png`, `.tiff`, `.tif`, `.bmp`, `.gif`, `.webp`.
* **Языки:** Сервис должен по умолчанию производить распознавание одновременно на **русском и английском языках**.
* **Отсутствие текста:** Если OCR-движок не обнаруживает текст на изображении, оно игнорируется.

**3.5. Обработка таблиц (`.xls`, `.xlsx`, `.csv`, `.ods`):**
* Данные из таблиц должны быть преобразованы в формат **CSV (Comma-Separated Values)**.
* Каждый лист таблицы конвертируется в отдельный блок, разделенный маркером.

**3.6. Обработка структурированных данных (`.xml`, `.yaml`, `.yml`, `.json`):**
* **XML файлы:** Извлекается содержимое всех элементов, атрибутов и текстовых узлов с сохранением иерархической структуры.
* **YAML/YML файлы:** Рекурсивно извлекаются все ключи и значения из конфигурационных файлов с указанием путей.
* **JSON файлы:** Извлекаются все строковые значения с указанием их пути в структуре данных.

**3.7. Обработка электронных книг и писем (`.epub`, `.eml`, `.msg`):**
* **EPUB файлы:** Извлекается текстовое содержимое из всех HTML/XHTML файлов с применением защиты от zip-бомб (ограничение размера распакованного архива до 100 МБ).
* **EML файлы:** Извлекаются заголовки письма (From, To, Subject, Date) и текстовое содержимое тела письма (как plain text, так и HTML).
* **MSG файлы:** Применяется эвристический анализ для извлечения читаемого текста из формата Outlook.

**3.8. Обработка исходного кода:**
* **Поддерживаемые языки программирования:** Python (`.py`, `.pyx`, `.pyi`, `.pyw`), JavaScript/TypeScript (`.js`, `.jsx`, `.ts`, `.tsx`, `.mjs`, `.cjs`), Java (`.java`, `.jav`), C/C++ (`.c`, `.cpp`, `.cxx`, `.cc`, `.c++`, `.h`, `.hpp`, `.hxx`, `.h++`), C# (`.cs`, `.csx`), PHP (`.php`, `.php3`, `.php4`, `.php5`, `.phtml`), Ruby (`.rb`, `.rbw`, `.rake`, `.gemspec`), Go (`.go`, `.mod`, `.sum`), Rust (`.rs`, `.rlib`), Swift (`.swift`), Kotlin (`.kt`, `.kts`), Scala (`.scala`, `.sc`), R (`.r`, `.R`, `.rmd`, `.Rmd`), SQL (`.sql`, `.ddl`, `.dml`), Shell (`.sh`, `.bash`, `.zsh`, `.fish`, `.ksh`, `.csh`, `.tcsh`), PowerShell (`.ps1`, `.psm1`, `.psd1`), Perl (`.pl`, `.pm`, `.pod`, `.t`), Lua (`.lua`), **1C:Enterprise (`.bsl`)**, **OneScript (`.os`)**, **Российские платформы разработки:** Специальная поддержка для файлов 1С:Предприятие и OneScript - популярных инструментов в российской IT-индустрии
* **Конфигурационные файлы:** INI (`.ini`), конфигурационные файлы (`.cfg`, `.conf`, `.config`), TOML (`.toml`), Properties (`.properties`)
* **Веб-технологии:** CSS (`.css`, `.scss`, `.sass`, `.less`, `.styl`)
* **Разметка и документация:** LaTeX (`.tex`, `.latex`), reStructuredText (`.rst`), AsciiDoc (`.adoc`, `.asciidoc`)
* **Специальные форматы:** JSON Lines (`.jsonl`, `.ndjson`), JSON с комментариями (`.jsonc`), Docker (`.dockerfile`, `.containerfile`), Makefile (`.makefile`, `.mk`, `.mak`), Git (`.gitignore`, `.gitattributes`, `.gitmodules`)
* **Обработка:** Файлы исходного кода обрабатываются с сохранением структуры и форматирования. Добавляется заголовок с указанием языка программирования, имени файла и количества строк для лучшего контекста при использовании в RAG-системах.

**3.9. Обработка архивов:**
* **Поддерживаемые форматы архивов:** `.zip`, `.rar`, `.7z`, `.tar`, `.gz`, `.bz2`, `.xz`, `.tgz`, `.tbz2`, `.txz`, `.tar.gz`, `.tar.bz2`, `.tar.xz`.
* **Стратегия обработки:** При обнаружении архивного файла система распаковывает его в отдельном процессе и обрабатывает каждый файл в архиве согласно его типу.
* **Безопасность:**
  * **Проверка размера архива:** Размер архива не должен превышать максимально допустимый размер файла (20 МБ).
  * **Защита от zip-бомб:** Максимальный размер распакованного содержимого ограничен 100 МБ.
  * **Защита от path traversal:** Имена файлов в архиве санитизируются для предотвращения атак типа directory traversal.
  * **Изоляция процесса:** Распаковка выполняется в отдельном процессе с таймаутом для предотвращения блокировки основного процесса.
  * **Контроль глубины вложенности:** Максимальная глубина вложенности архивов составляет 3 уровня.
* **Обработка файлов:** Каждый файл в архиве обрабатывается согласно его типу (документы, изображения, исходный код и т.д.).
* **Фильтрация файлов:** Игнорируются системные файлы (.DS_Store, Thumbs.db, .git/), временные файлы и папки.
* **Контроль временных файлов:** Все временные файлы и папки, созданные во время распаковки, автоматически удаляются после завершения обработки.

**3.10. Обработка веб-страниц и URL-файлов (новая функциональность v1.10.0, расширена в v1.10.1, v1.10.3):**
* **Универсальная обработка URL (v1.10.3)**: Автоматическое определение типа контента по URL - HTML страницы или файлы
* **URL-адреса**: Извлечение текста непосредственно с веб-страниц по указанному URL
* **Текстовое содержимое**: Извлекается весь текстовый контент HTML-страницы с удалением разметки, скриптов и стилей
* **Автоопределение кодировки**: Автоматическое определение кодировки страницы для корректного отображения текста
* **Обработка изображений на странице**:
  * Поиск всех изображений в тегах `<img>` с извлечением URL
  * Обработка относительных путей к изображениям (конвертация в абсолютные URL)
  * **Поддержка base64 изображений (v1.10.1)**: 
    * Автоматическое обнаружение и декодирование встроенных изображений в формате `data:image/...;base64,...`
    * Извлечение MIME-типа из data URI и проверка поддерживаемых форматов
    * Валидация размера изображения (минимум 150x150 пикселей, настраивается через `MIN_IMAGE_SIZE_FOR_OCR`)
    * Применение OCR к крупным изображениям с автоматическим определением размеров
    * **Безопасная обработка**: Проверка целостности base64 данных и защита от некорректного декодирования
  * Загрузка изображений размером больше минимального (150x150 пикселей, настраивается через `MIN_IMAGE_SIZE_FOR_OCR`)
  * Применение OCR к крупным изображениям аналогично обработке PDF
  * Ограничение количества обрабатываемых изображений (до 20 на страницу, настраивается через `MAX_IMAGES_PER_PAGE`)
  * Параллельная загрузка изображений (до 2 одновременно для оптимизации производительности)
* **JavaScript рендеринг с Playwright (v1.10.1)**:
  * **Полная поддержка современных веб-технологий**: SPA (Single Page Applications), React, Vue.js, Angular приложений
  * **Chromium headless engine**: Использование реального браузера для рендеринга JavaScript
  * **Автоматическое выполнение JavaScript**: Ожидание полной загрузки страницы и стабилизации DOM
  * **Умная обработка lazy loading**: 
    * Автоматический безопасный скролл для активации ленивой загрузки изображений
    * Мониторинг изменений высоты страницы для определения завершения загрузки контента
    * Умная стабилизация: ожидание прекращения изменений DOM после скролла
  * **Защита от бесконечного скролла**: 
    * Ограничение количества попыток скролла (настраивается через `MAX_SCROLL_ATTEMPTS`)
    * Таймауты для предотвращения зависания на бесконечных лентах
    * Детекция зацикленного контента и автоматическое прерывание
  * **Fallback механизм**: Автоматическое переключение на стандартный HTTP-клиент при ошибках Playwright
  * **Настраиваемые таймауты**: Отдельные таймауты для загрузки страницы и выполнения JavaScript
* **Безопасность**:
  * Комплексная защита от SSRF-атак:
    * Hostname-based блокировка: localhost, host.docker.internal, ip6-localhost, ip6-loopback
    * IP-based блокировка: localhost (127.0.0.0/8), частные сети (10.0.0.0/8, 192.168.0.0/16), Docker сети (172.16.0.0/12), IPv6 loopback (::1/128, fe80::/10)
    * Блокировка metadata service (169.254.169.254) для защиты в облачных средах (AWS/GCP)
    * Блокировка Docker bridge gateway (172.x.0.1)
    * Автоматическая проверка на loopback, private и link-local адреса
    * Проверка всех IP-адресов хоста (IPv4 и IPv6)
  * Следование HTTP-редиректам с ограничением количества переходов
  * Настраиваемый User-Agent для корректной работы с различными сайтами
* **Таймауты**:
  * Таймаут загрузки страницы (настраивается через `WEB_PAGE_TIMEOUT`)
  * Таймаут загрузки изображений (настраивается через `IMAGE_DOWNLOAD_TIMEOUT`)
  * **Отдельный таймаут для JS-рендеринга (v1.10.1)**: Настраивается через `JS_RENDER_TIMEOUT`
  * **Таймаут HEAD запроса (v1.10.3)**: Настраивается через `HEAD_REQUEST_TIMEOUT` (по умолчанию: 10 секунд)
  * **Таймаут скачивания файлов (v1.10.3)**: Настраивается через `FILE_DOWNLOAD_TIMEOUT` (по умолчанию: 60 секунд)
* **Автоматическое определение типа контента (v1.10.3)**:
  * **HEAD запрос**: Выполнение HEAD запроса для определения Content-Type без загрузки всего файла
  * **Следование редиректам**: Поддержка HTTP-редиректов при определении типа контента с настраиваемым лимитом переходов
  * **Fallback на GET**: При ошибке HEAD запроса автоматическое переключение на GET с чтением только заголовков
  * **Приоритет Content-Type**: Основной способ определения - анализ MIME-типа из HTTP заголовков
  * **Fallback на расширение URL**: При неопределенном Content-Type использование расширения из URL
  * **Magic numbers**: После скачивания файла дополнительная проверка соответствия содержимого заявленному типу
* **Скачивание и обработка файлов (v1.10.3)**:
  * **Поддерживаемые форматы**: Все форматы, поддерживаемые эндпоинтом `/v1/extract/file`
  * **Потоковое скачивание**: Загрузка файлов порциями с проверкой размера в процессе
  * **Контроль размера**: Проверка размера файла через Content-Length и во время скачивания
  * **Безопасность**: Применение тех же мер безопасности что и для загружаемых файлов (лимиты размера, проверка MIME-типов)
  * **Определение имени файла**: Извлечение имени из заголовка Content-Disposition или URL с санитизацией
  * **Временные файлы**: Автоматическое создание и удаление временных файлов с гарантированной очисткой
  * **Переиспользование логики**: Использование существующих методов извлечения текста после скачивания файла

**3.11. Обработка прочих форматов (`.txt`, `.html`, `.md` и др.):**
* Извлекается текстовое содержимое. Из форматов с разметкой разметка удаляется.

### 4. Требования к API

**4.0. Базовый URL:**
* Для локальной разработки Сервис должен быть доступен по адресу `http://localhost:7555`.

**4.1. Эндпоинт `GET /` — Информация о API**
* **Ответ (`HTTP 200 OK`):**
```json
{
  "api_name": "Text Extraction API for RAG",
  "version": "1.9.0",
  "contact": "Барилко Виталий"
}
```

**4.2. Эндпоинт `GET /health` — Проверка состояния**
* **Ответ (`HTTP 200 OK`):**
```json
{
  "status": "ok"
}
```

**4.3. Эндпоинт `GET /v1/supported-formats` — Поддерживаемые форматы**
* **Ответ (`HTTP 200 OK`):**
```json
{
  "images_ocr": ["jpg", "jpeg", "png", "tiff", "tif", "bmp", "gif", "webp"],
  "documents": ["doc", "docx", "pdf", "rtf", "odt"],
  "spreadsheets": ["csv", "xls", "xlsx", "ods"],
  "presentations": ["pptx", "ppt"],
  "structured_data": ["json", "xml", "yaml", "yml"],
  "source_code": ["py", "js", "ts", "java", "c", "cpp", "h", "cs", "php", "rb", "go", "rs", "swift", "kt", "scala", "sql", "sh", "ps1", "pl", "lua", "bsl", "os", "ini", "css", "tex", "dockerfile", "makefile", "gitignore"],
  "other": ["txt", "html", "htm", "md", "markdown", "epub", "eml", "msg"],
  "archives": ["zip", "rar", "7z", "tar", "gz", "bz2", "xz", "tgz", "tbz2", "txz", "tar.gz", "tar.bz2", "tar.xz"]
}
```

**4.4. Эндпоинт `POST /v1/extract/base64` — Извлечение текста из base64-файла**
* **Метод:** `POST`.
* **Тело запроса:** `application/json` с полями `encoded_base64_file` и `filename`.
* **Формат запроса:**
```json
{
  "encoded_base64_file": "SGVsbG8gV29ybGQ=",
  "filename": "document.pdf"
}
```
* **Успешный ответ (`HTTP 200 OK`):**
```json
{
  "status": "success",
  "filename": "document.pdf",
  "count": 1,
  "files": [
    {
      "filename": "document.pdf",
      "path": "document.pdf",
      "size": 1024000,
      "type": "pdf",
      "text": "Полностью извлеченный и скомбинированный текст..."
    }
  ]
}
```

* **Успешный ответ для архива (`HTTP 200 OK`):**
```json
{
  "status": "success",
  "filename": "documents.zip",
  "count": 2,
  "files": [
    {
      "filename": "document1.pdf",
      "path": "documents/document1.pdf",
      "size": 524288,
      "type": "pdf",
      "text": "Текст из первого документа..."
    },
    {
      "filename": "image1.jpg",
      "path": "documents/images/image1.jpg",
      "size": 102400,
      "type": "jpg",
      "text": "Распознанный текст с изображения..."
    }
  ]
}
```
* **Ответы с ошибкой:**
    * **`400 Bad Request`**: Неверный формат base64 или некорректный запрос.
    * **`413 Payload Too Large`**: Файл превышает максимальный размер.
    * **`415 Unsupported Media Type`**: Формат файла не поддерживается или расширение файла не соответствует его содержимому.
    * **`422 Unprocessable Entity`**: Файл поврежден, пуст или защищен паролем.
    * **`504 Gateway Timeout`**: Обработка файла превысила установленный лимит времени.
    
    Примеры ответов с ошибкой:
```json
{
  "status": "error",
  "filename": "document.pdf",
  "message": "Неверный формат base64. Убедитесь, что файл корректно закодирован в base64."
}
```

```json
{
  "status": "error",
  "filename": "malicious.txt",
  "message": "Расширение файла не соответствует его содержимому. Возможная подделка типа файла."
}
```

```json
{
  "status": "error",
  "filename": "broken.docx",
  "message": "Файл поврежден или формат не поддерживается."
}
```

**4.5. Эндпоинт `POST /v1/extract/file` — Извлечение текста**
* **Метод:** `POST`.
* **Тело запроса:** `multipart/form-data` с полем `file`.
* **Успешный ответ (`HTTP 200 OK`):**
```json
{
  "status": "success",
  "filename": "invoice.pdf",
  "count": 1,
  "files": [
    {
      "filename": "invoice.pdf",
      "path": "invoice.pdf",
      "size": 1024000,
      "type": "pdf",
      "text": "Полностью извлеченный и скомбинированный текст..."
    }
  ]
}
```

* **Успешный ответ для архива (`HTTP 200 OK`):**
```json
{
  "status": "success",
  "filename": "documents.zip",
  "count": 2,
  "files": [
    {
      "filename": "document1.pdf",
      "path": "documents/document1.pdf",
      "size": 524288,
      "type": "pdf",
      "text": "Текст из первого документа..."
    },
    {
      "filename": "image1.jpg",
      "path": "documents/images/image1.jpg",
      "size": 102400,
      "type": "jpg",
      "text": "Распознанный текст с изображения..."
    }
  ]
}
```
* **Ответы с ошибкой:**
    * **`400 Bad Request`**: Отсутствует заголовок Content-Length или некорректный запрос.
    * **`413 Payload Too Large`**: Файл превышает максимальный размер.
    * **`415 Unsupported Media Type`**: Формат файла не поддерживается, обнаружен архив, или расширение файла не соответствует его содержимому.
    * **`422 Unprocessable Entity`**: Файл поврежден, пуст или защищен паролем.
    * **`504 Gateway Timeout`**: Обработка файла превысила установленный лимит времени.
    
    Примеры ответов с ошибкой:
```json
{
  "status": "error",
  "filename": "document.pdf",
  "message": "Отсутствует заголовок Content-Length. Пожалуйста, убедитесь, что размер файла указан в запросе."
}
```

```json
{
  "status": "error",
  "filename": "malicious.txt",
  "message": "Расширение файла не соответствует его содержимому. Возможная подделка типа файла."
}
```

```json
{
  "status": "error",
  "filename": "broken.docx",
  "message": "Файл поврежден или формат не поддерживается."
}
```

**4.6. Эндпоинт `POST /v1/extract/url` — Извлечение текста с веб-страниц и файлов по URL (новая функциональность v1.10.0, расширена в v1.10.2, v1.10.3)**
* **Метод:** `POST`.
* **Тело запроса:** `application/json` с полями `url`, опциональным `user_agent` и опциональным объектом `extraction_options` (новое в v1.10.2).
* **Формат запроса (базовый, для обратной совместимости):**
```json
{
  "url": "https://example.com/page",
  "user_agent": "Text Extraction Bot 1.0"
}
```
* **Формат запроса (расширенный с настройками извлечения, новое в v1.10.2):**
```json
{
  "url": "https://example.com/page",
  "user_agent": "Text Extraction Bot 1.0",
  "extraction_options": {
    "enable_javascript": true,
    "js_render_timeout": 15,
    "web_page_delay": 2,
    "enable_lazy_loading_wait": false,
    "max_scroll_attempts": 1,
    "process_images": true,
    "enable_base64_images": true,
    "min_image_size_for_ocr": 30000,
    "max_images_per_page": 10,
    "web_page_timeout": 20,
    "image_download_timeout": 10,
    "follow_redirects": true,
    "max_redirects": 3
  }
}
```

**Описание параметров extraction_options (новое в v1.10.2):**

Все параметры в объекте `extraction_options` являются **опциональными**. При отсутствии используются значения по умолчанию из переменных окружения. Параметры предоставляют полный контроль над процессом извлечения текста с веб-страниц на уровне отдельного запроса.

**JavaScript и рендеринг:**
* `enable_javascript` (boolean): Включить/выключить JavaScript рендеринг с помощью Playwright. По умолчанию: `false`
* `js_render_timeout` (integer): Таймаут для ожидания завершения JS-рендеринга в секундах. По умолчанию: `10`
* `web_page_delay` (integer): Дополнительная задержка после завершения JS в секундах. По умолчанию: `3`

**Lazy Loading и скролл:**
* `enable_lazy_loading_wait` (boolean): Включить автоматический скролл для активации ленивой загрузки изображений. По умолчанию: `true`
* `max_scroll_attempts` (integer): Максимальное количество попыток скролла (0 = без скролла). По умолчанию: `3`

**Обработка изображений:**
* `process_images` (boolean): Обрабатывать ли изображения через OCR. По умолчанию: `true`
* `enable_base64_images` (boolean): Обрабатывать ли встроенные base64 изображения. По умолчанию: `true`
* `min_image_size_for_ocr` (integer): Минимальный размер изображения в пикселях для OCR. По умолчанию: `22500` (150x150)
* `max_images_per_page` (integer): Максимальное количество изображений для обработки на странице. По умолчанию: `20`

**Таймауты:**
* `web_page_timeout` (integer): Таймаут загрузки веб-страницы в секундах. По умолчанию: `30`
* `image_download_timeout` (integer): Таймаут загрузки каждого изображения в секундах. По умолчанию: `15`

**Сетевые настройки:**
* `follow_redirects` (boolean): Следовать ли HTTP-редиректам. По умолчанию: `true`
* `max_redirects` (integer): Максимальное количество редиректов (только для requests, не Playwright)

**Приоритет настроек:**
1. Параметры в `extraction_options` (высший приоритет)
2. Переменные окружения (по умолчанию)

**User-Agent:** Используется параметр `user_agent` на корневом уровне запроса.

* **Успешный ответ для HTML страницы (`HTTP 200 OK`):**
```json
{
  "status": "success",
  "url": "https://example.com/page",
  "count": 3,
  "files": [
    {
      "filename": "page_content",
      "path": "https://example.com/page",
      "size": 45670,
      "type": "html",
      "text": "Основной текст страницы..."
    },
    {
      "filename": "image1.jpg",
      "path": "https://example.com/images/photo1.jpg", 
      "size": 234567,
      "type": "jpg",
      "text": "Текст с изображения через OCR..."
    },
    {
      "filename": "image2.png",
      "path": "https://example.com/images/chart.png",
      "size": 189432,
      "type": "png", 
      "text": "Распознанный текст с графика..."
    }
  ]
}
```

* **Успешный ответ для скачанного файла (новое в v1.10.3, `HTTP 200 OK`):**
```json
{
  "status": "success",
  "url": "https://example.com/document.pdf",
  "count": 1,
  "files": [
    {
      "filename": "document.pdf",
      "path": "document.pdf",
      "size": 1024000,
      "type": "pdf",
      "text": "Извлеченный текст из скачанного PDF документа..."
    }
  ]
}
```

* **Успешный ответ для скачанного архива (новое в v1.10.3, `HTTP 200 OK`):**
```json
{
  "status": "success",
  "url": "https://example.com/files.zip",
  "count": 2,
  "files": [
    {
      "filename": "document1.docx",
      "path": "files/document1.docx",
      "size": 524288,
      "type": "docx",
      "text": "Текст из первого документа в архиве..."
    },
    {
      "filename": "image1.jpg",
      "path": "files/images/image1.jpg",
      "size": 102400,
      "type": "jpg",
      "text": "Распознанный текст с изображения из архива..."
    }
  ]
}
```
* **Ответы с ошибкой:**
    * **`400 Bad Request`**: Некорректный URL или недоступный для обработки адрес (внутренние IP).
    * **`404 Not Found`**: Страница не найдена или сервер недоступен.
    * **`422 Unprocessable Entity`**: Ошибка парсинга HTML или извлечения текста.
    * **`504 Gateway Timeout`**: Превышен лимит времени загрузки страницы или изображений.
    
    Примеры ответов с ошибкой:
```json
{
  "status": "error",
  "url": "http://192.168.1.1/page",
  "message": "Доступ к внутренним IP-адресам запрещен из соображений безопасности."
}
```

```json
{
  "status": "error",
  "url": "https://example.com/page",
  "message": "Не удалось загрузить страницу: Connection timeout."
}
```

```json
{
  "status": "error",
  "url": "https://example.com/broken-page",
  "message": "Ошибка парсинга HTML: Invalid document structure."
}
```

**4.7. Документация API (Swagger UI):**
* Сервис должен предоставлять интерактивную документацию API, автоматически генерируемую фреймворком FastAPI.
* Интерактивная документация должна быть доступна по адресу `http://localhost:7555/docs`.

### 5. Нефункциональные требования

**5.1. Производительность:**
* **Максимальный размер файла:** **20 МБ**.
* **Таймаут обработки:** **300 секунд (5 минут)**. При превышении — возврат ошибки `504 Gateway Timeout`.
* **Многопроцессорность:** Для максимальной производительности рекомендуется использовать несколько worker-процессов uvicorn. Количество процессов настраивается переменной окружения `WORKERS`. Общепринятая практика для продакшена — использовать формулу: 2 * (количество ядер CPU) + 1.

**5.2. Асинхронность и производительность:**
* **Неблокирующая обработка:** Все CPU-bound операции (OCR, парсинг PDF, конвертация документов, работа с архивами, обработка изображений) ОБЯЗАТЕЛЬНО должны выполняться в отдельном пуле потоков для предотвращения блокировки event loop.
* **Использование run_in_threadpool:** Для выполнения синхронных операций используется `fastapi.concurrency.run_in_threadpool` или аналогичные механизмы.
* **Стабильность API:** Сервер должен оставаться отзывчивым и способным обрабатывать новые запросы даже во время обработки больших или сложных файлов.
* **Изоляция операций:** Каждая операция извлечения текста должна быть полностью изолирована, чтобы сбой в одной операции не влиял на другие.

**5.3. Безопасность:**
* **Аутентификация:** Не требуется, поскольку сервис предназначен для использования исключительно внутри корпоративной сети предприятия с контролируемым доступом.
* **Политика CORS:** Используется открытая политика CORS (`allow_origins=["*"]`) для максимальной совместимости с различными внутренними клиентскими приложениями в корпоративной среде.
* **Санитизация имен файлов:** Система должна очищать имена файлов от потенциально опасных символов и путей (например, `../`, `./`, специальные символы) для предотвращения атак типа path traversal. Используется библиотека `werkzeug.utils.secure_filename` или аналогичные методы санитизации.
* **Проверка MIME-типов (улучшено в v1.10.1):** 
  * Система использует универсальную функцию `get_extension_from_mime()` для сопоставления MIME-типов с поддерживаемыми расширениями
  * Автоматическая проверка соответствия содержимого файла заявленному расширению для предотвращения атак через подделку типа файла
  * **Динамическая валидация**: Проверка MIME-типов теперь основана на конфигурации `SUPPORTED_FORMATS` вместо жестко закодированных значений
  * При несоответствии расширения файла и его реального MIME-типа система логирует предупреждение и отклоняет файл с кодом ошибки `415 Unsupported Media Type`
  * **Поддержка base64 data URI**: Автоматическое извлечение и валидация MIME-типов из base64-кодированных изображений
* **Защита от DoS-атак:** Система обязательно проверяет наличие заголовка `Content-Length` в запросе. Если размер файла не указан (`file.size` равен `None`), запрос отклоняется с кодом ошибки `400 Bad Request`. Это предотвращает загрузку файлов произвольного размера в память и защищает от атак типа "отказ в обслуживании".
* **Защита от zip-бомб:** При обработке архивных форматов применяется ограничение на размер распакованного содержимого (100 МБ) для предотвращения атак типа "zip-бомба".
* **Контроль временных файлов:** Все временные файлы и папки, создаваемые во время обработки, должны автоматически удаляться после завершения операции с использованием контекстных менеджеров Python. Система должна гарантировать освобождение дискового пространства даже при возникновении исключений.

#### 5.3.1. Рекомендации по управлению ресурсами
* **Принцип "гарантированной очистки":** Всегда используйте блоки `try...finally` или контекстные менеджеры для работы с временными файлами. Удаление временных файлов должно происходить в блоке `finally`, чтобы гарантировать освобождение ресурсов даже при возникновении исключений.
  ```python
  temp_file_path = None
  try:
      with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_file:
          temp_file_path = temp_file.name
          # обработка файла
  finally:
      if temp_file_path and os.path.exists(temp_file_path):
          try:
              os.unlink(temp_file_path)
          except OSError as e:
              logger.warning(f"Не удалось удалить временный файл: {str(e)}")
  ```

* **Принцип "fail-closed" для валидации:** При любых ошибках валидации файлов (определение MIME-типа, проверка соответствия расширения) система должна отклонять файл, а не пропускать его. Это повышает безопасность за счет блокировки потенциально подозрительных файлов.
  ```python
  try:
      # валидация файла
      return True, None
  except Exception as e:
      # В случае ошибки - отклоняем файл (fail-closed)
      logger.warning(f"Ошибка валидации: {str(e)}")
      return False, f"Не удалось определить тип файла: {str(e)}"
  ```

* **Очистка при старте:** Приложение должно автоматически очищать старые временные файлы при запуске, удаляя файлы старше 1 часа для предотвращения накопления "мусора" от предыдущих запусков.

#### 5.3.2. Рекомендации по настройке CORS для корпоративной среды
* **Обоснование открытой политики:** API предназначен для использования исключительно внутри корпоративной сети предприятия, где риски CSRF и других межсайтовых атак минимизированы контролируемой сетевой средой.
  ```python
  app.add_middleware(
      CORSMiddleware,
      allow_origins=["*"],  # Разрешено для внутренней сети
      allow_credentials=True,
      allow_methods=["*"],
      allow_headers=["*"],
  )
  ```

* **Контекст использования:** 
  - Сервис работает в изолированной корпоративной сети
  - Доступ к API контролируется сетевыми политиками предприятия
  - Клиентские приложения могут работать с различных внутренних доменов и портов
  - Максимальная совместимость важнее строгих CORS-ограничений

* **Альтернативная конфигурация для внешней среды:** Если сервис планируется выставить во внешнюю сеть, необходимо ограничить CORS:
  ```python
  # Для продакшена с внешним доступом
  allow_origins=[
      "https://company-domain.com",
      "https://api.company-domain.com"
  ]
  ```

* **Сетевая безопасность:** Основная защита обеспечивается на уровне сетевой инфраструктуры предприятия (фаерволы, VPN, изоляция сегментов сети), а не CORS-политиками.

#### 5.3.3. Рекомендации по защите от DoS атак через дочерние процессы
* **Проблема:** Внешние утилиты (LibreOffice, Tesseract) могут потреблять чрезмерное количество памяти при обработке специально подготовленных "файлов-бомб", что может привести к отказу в обслуживании.

* **Многоуровневая защита:**
  - **Уровень 1:** Ограничения на уровне Docker контейнера (базовая защита)
  - **Уровень 2:** Ограничения на уровне дочерних процессов (гранулярное управление)
  - **Уровень 3:** Предварительная валидация файлов и изображений

* **Ограничения ресурсов для дочерних процессов:**
  ```python
  # Функция для запуска процессов с ограничениями
  def run_subprocess_with_limits(command, memory_limit=None, timeout=30):
      def preexec_fn():
          # Ограничение виртуальной памяти
          resource.setrlimit(resource.RLIMIT_AS, (memory_limit, memory_limit))
          # Ограничение времени CPU
          resource.setrlimit(resource.RLIMIT_CPU, (timeout * 2, timeout * 2))
      
      return subprocess.run(command, preexec_fn=preexec_fn, timeout=timeout)
  ```

* **Переменные окружения для настройки защиты:**
  - `ENABLE_RESOURCE_LIMITS=true` - включить/выключить ограничения
  - `MAX_LIBREOFFICE_MEMORY=1610612736` - лимит памяти для LibreOffice (1.5GB)
  - `MAX_TESSERACT_MEMORY=536870912` - лимит памяти для Tesseract (512MB)
  - `MAX_OCR_IMAGE_PIXELS=52428800` - максимальное разрешение изображений для OCR (50MP)

* **Рекомендации по размерам лимитов:**
  - **Малые системы (2-4GB RAM):** LibreOffice: 1GB, Tesseract: 256MB
  - **Средние системы (8-16GB RAM):** LibreOffice: 2GB, Tesseract: 512MB
  - **Крупные системы (32GB+ RAM):** LibreOffice: 4GB, Tesseract: 1GB

* **Docker-контейнер с ограничениями:**
  ```yaml
  # docker-compose.yml
  services:
    extract-text:
      mem_limit: 4G                    # Общий лимит контейнера
      mem_reservation: 1G              # Минимальная память
      deploy:
        resources:
          limits:
            memory: 4G
            cpus: "2.0"
  ```

* **Валидация изображений для OCR:**
  ```python
  def validate_image_for_ocr(image_content):
      with Image.open(io.BytesIO(image_content)) as img:
          # Проверка разрешения
          if img.width * img.height > MAX_OCR_IMAGE_PIXELS:
              raise ValueError("Image too large for OCR")
          # Проверка формата и цветового режима
          if img.format not in ['JPEG', 'PNG', 'TIFF', 'BMP']:
              raise ValueError("Unsupported image format")
  ```

* **Обработка ошибок превышения лимитов:**

- Процессы, превышающие лимит памяти, завершаются с кодом 137 (SIGKILL)
- Система логирует превышения и возвращает понятные ошибки пользователю
- Временные файлы очищаются в блоках `finally` даже при ошибках

* **Безопасный вызов Tesseract для OCR:**
  ```python
  def _safe_tesseract_ocr(self, image, temp_image_path: str = None) -> str:
      # Создание временного файла изображения
      with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:
          image.save(temp_file.name, 'PNG')
      
      # Безопасный вызов tesseract через run_subprocess_with_limits
      result = run_subprocess_with_limits(
          command=['tesseract', temp_image_path, output_path, '-l', languages],
          timeout=30,
          memory_limit=settings.MAX_TESSERACT_MEMORY,
          capture_output=True
      )
  ```

* **Все вызовы Tesseract защищены:**
  - `_extract_from_image_sync()` - OCR обычных изображений
  - `_ocr_from_pdf_image_sync()` - OCR изображений из PDF файлов
  - Заменен небезопасный `pytesseract.image_to_string()` на `_safe_tesseract_ocr()`
  - Предотвращены DoS атаки через специально подготовленные изображения

#### 5.3.5. Функциональные исправления и соответствие ТЗ

**5.3.5.1. Таймаут для архивов (версия 1.8.6)**
* **Проблема:** Отсутствие таймаута 300 секунд для обработки архивов, что нарушало пункт 5.1 ТЗ.
* **Решение:** Добавлен `asyncio.wait_for()` с таймаутом 300 секунд для всех операций обработки файлов, включая архивы.
* **Реализация:**
  ```python
  # В app/main.py - применение таймаута к обработке
  extracted_files = await asyncio.wait_for(
      run_in_threadpool(
          text_extractor.extract_text, content, safe_filename_for_processing
      ),
      timeout=settings.PROCESSING_TIMEOUT_SECONDS  # 300 секунд согласно ТЗ п.5.1
  )
  ```
* **Результат:** При превышении 300 секунд система возвращает ошибку `504 Gateway Timeout` согласно требованиям ТЗ.

**5.3.5.2. Полное извлечение из DOCX документов (версия 1.8.6)**
* **Проблема:** Неполное извлечение текста из DOCX файлов - отсутствие колонтитулов, сносок и комментариев, что нарушало пункт 3.3 ТЗ.
* **Решение:** Расширен метод `_extract_from_docx_sync()` для полного извлечения всех элементов документа.
* **Реализация:**
  ```python
  # Колонтитулы (headers и footers)
  for section in doc.sections:
      if section.header:
          # Извлечение заголовка
      if section.footer:
          # Извлечение подвала
  
  # Сноски
  if hasattr(doc, 'footnotes') and doc.footnotes:
      # Извлечение сносок
  
  # Комментарии
  if hasattr(doc, 'comments') and doc.comments:
      # Извлечение комментариев
  ```
* **Результат:** Полное соответствие пункту 3.3 ТЗ - извлечение текста из основного тела документа, колонтитулов, сносок и комментариев.

**5.3.5.3. Полное извлечение из PPTX презентаций (версия 1.8.6)**
* **Проблема:** Неполное извлечение текста из PPTX файлов - отсутствие заметок спикера, что нарушало пункт 3.3 ТЗ.
* **Решение:** Расширен метод `_extract_from_pptx_sync()` для извлечения заметок спикера с каждого слайда.
* **Реализация:**
  ```python
  # Извлечение заметок спикера
  if hasattr(slide, 'notes_slide') and slide.notes_slide:
      notes_text = []
      for shape in slide.notes_slide.shapes:
          if hasattr(shape, 'text') and shape.text.strip():
              if shape.text.strip() not in ['Заметки', 'Notes']:
                  notes_text.append(shape.text.strip())
      
      if notes_text:
          slide_text.append(f"[Заметки спикера]\n{' '.join(notes_text)}")
  ```
* **Результат:** Полное соответствие пункту 3.3 ТЗ - извлечение текста из слайдов и заметок спикера.

#### 5.3.4. Архитектура производительности и Event Loop
* **Критическое требование:** Все ресурсоемкие операции должны выполняться вне основного потока Event Loop для предотвращения блокировки сервера.

* **Проблема блокировки Event Loop:**
  - Обработка архивов (.zip, .rar, .7z, .tar и т.д.) включает блокирующие операции (`zipfile.ZipFile`, `tarfile.open`, `rarfile.RarFile`, `shutil.copyfileobj`)
  - Эти операции могут занять секунды или минуты, полностью блокируя сервер
  - Пока один архив обрабатывается, сервер не может принимать новые запросы

* **Архитектурное решение:**
  ```python
  # В app/main.py - основной контроллер
  from fastapi.concurrency import run_in_threadpool
  
  @app.post("/v1/extract/file")
  async def extract_text(file: UploadFile = File(...)):
      # Весь процесс извлечения выполняется в пуле потоков
      extracted_files = await run_in_threadpool(
          text_extractor.extract_text, content, safe_filename_for_processing
      )
  ```

* **Синхронная реализация экстракторов:**
  ```python
  # В app/extractors.py - все методы синхронные
  def extract_text(self, file_content: bytes, filename: str) -> List[Dict[str, Any]]:
      # Синхронная обработка в отдельном потоке
      if is_archive_format(filename, settings.SUPPORTED_FORMATS):
          return self._extract_from_archive(file_content, filename)
      
      # Остальная обработка также синхронная
      text = self._extract_text_by_format(file_content, extension, filename)
  ```

* **Преимущества архитектуры:**
  - **Неблокирующий Event Loop:** Основной поток FastAPI остается свободным для обработки других запросов
  - **Параллельная обработка:** Несколько файлов могут обрабатываться одновременно в разных потоках
  - **Масштабируемость:** Сервер может обрабатывать сотни запросов параллельно, даже если некоторые из них долгие
  - **Стабильность:** Ошибки в одном потоке не влияют на другие запросы

* **Контроль ресурсов:**
  - Используется `ThreadPoolExecutor` с ограниченным количеством потоков
  - Предотвращает создание слишком большого количества потоков
  - Автоматическое управление жизненным циклом потоков

* **Мониторинг производительности:**
  - Логирование времени обработки каждого файла
  - Отслеживание состояния пула потоков
  - Метрики для мониторинга загрузки системы

**5.4. Среда развертывания:**
* Сервис должен поставляться в виде **Docker-контейнера**.

#### 5.4.1. Рекомендации по Docker развертыванию
* **Обязательный HEALTHCHECK:** Docker образ должен содержать инструкцию HEALTHCHECK для автоматического мониторинга работоспособности приложения системами оркестрации (Kubernetes, Docker Swarm).
  ```dockerfile
  HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:7555/health || exit 1
  ```

* **Многоэтапная сборка (Multi-stage build):** Используйте многоэтапную сборку для оптимизации размера образа и повышения безопасности:
  - **Builder stage:** установка зависимостей и сборочных инструментов
  - **Production stage:** копирование готовых пакетов без сборочных инструментов
  ```dockerfile
  # Этап сборки
  FROM python:3.11-slim AS builder
  RUN apt-get update && apt-get install -y build-essential
  COPY requirements.txt .
  RUN pip install --user -r requirements.txt
  
  # Производственный этап  
  FROM python:3.11-slim AS production
  COPY --from=builder /root/.local /home/appuser/.local
  # остальная настройка...
  ```

* **Необходимые системные пакеты:** Производственный образ должен включать `curl` для работы HEALTHCHECK и все необходимые рабочие зависимости (tesseract, libreoffice, antiword, libmagic1).

* **Безопасность контейнера:** Всегда запускайте приложение от непривилегированного пользователя (`appuser`), устанавливайте корректные права доступа к файлам и директориям.

**5.5. Логирование:**
* Сервис должен вести структурированные логи (запросы, ошибки с traceback).

#### 5.5.1. Рекомендации по инициализации приложения
* **Lifecycle manager:** Используйте FastAPI lifespan events для выполнения задач инициализации и завершения работы приложения.
  ```python
  @asynccontextmanager
  async def lifespan(app: FastAPI):
      # Инициализация при старте
      logger.info(f"Запуск Text Extraction API v{settings.VERSION}")
      cleanup_temp_files()  # Очистка старых временных файлов
      yield
      # Завершение работы
      logger.info("Завершение работы Text Extraction API")
  ```

* **Автоматическая очистка:** При каждом запуске приложения должна выполняться очистка временных файлов от предыдущих сессий для предотвращения накопления "мусора" и улучшения производительности.

* **Логирование инициализации:** Всегда логируйте важные этапы инициализации приложения, включая версию, настройки и результаты очистки.

**5.6. Конфигурация и Воспроизводимость:**
* **Переменные окружения:** Ключевые параметры должны задаваться через переменные окружения для гибкой настройки без пересборки образа.
    * `API_PORT` (по умолчанию: 7555)
    * `OCR_LANGUAGES` (по умолчанию: rus+eng)
    * `PROCESSING_TIMEOUT_SECONDS` (по умолчанию: 300)
    * `CPU_CORES` (по умолчанию: 4, используется для автоматического расчета количества воркеров в продакшене)
    * `WORKERS` (по умолчанию: 1 для разработки, для продакшена автоматически вычисляется как 2 * CPU_CORES + 1)
    * `MAX_ARCHIVE_SIZE` (по умолчанию: 20971520 - 20 МБ)
    * `MAX_EXTRACTED_SIZE` (по умолчанию: 104857600 - 100 МБ)
    * `MAX_ARCHIVE_NESTING` (по умолчанию: 3)
    * **Настройки веб-экстрактора (v1.10.0):**
        * `MIN_IMAGE_SIZE_FOR_OCR` (по умолчанию: 22500 - 150x150 пикселей)
        * `MAX_IMAGES_PER_PAGE` (по умолчанию: 20)
        * `WEB_PAGE_TIMEOUT` (по умолчанию: 30 секунд)
        * `IMAGE_DOWNLOAD_TIMEOUT` (по умолчанию: 15 секунд)
        * `DEFAULT_USER_AGENT` (по умолчанию: "Text Extraction Bot 1.0")
        * `ENABLE_JAVASCRIPT` (по умолчанию: false)
        * `BLOCKED_IP_RANGES` (по умолчанию: "127.0.0.0/8,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16,169.254.0.0/16,::1/128,fe80::/10")
        * `BLOCKED_HOSTNAMES` (по умолчанию: "localhost,host.docker.internal,ip6-localhost,ip6-loopback")
    * **Настройки веб-экстрактора v1.10.1 (Playwright):**
        * `ENABLE_BASE64_IMAGES` (по умолчанию: true) - обработка base64 изображений
        * `WEB_PAGE_DELAY` (по умолчанию: 3 секунды) - задержка после загрузки JS
        * `ENABLE_LAZY_LOADING_WAIT` (по умолчанию: true) - ожидание lazy loading
        * `JS_RENDER_TIMEOUT` (по умолчанию: 10 секунд) - таймаут JS-рендеринга
        * `MAX_SCROLL_ATTEMPTS` (по умолчанию: 3) - защита от бесконечного скролла
* **Фиксация зависимостей:** Проект должен содержать файл `requirements.txt` с зафиксированными версиями всех Python-библиотек для обеспечения воспроизводимости сборок.

### 6. Рекомендуемый технологический стек

* **Язык:** Python 3.10+
* **Веб-фреймворк:** FastAPI
* **Веб-сервер:** Uvicorn
* **Веб-автоматизация:** Playwright (Chromium headless для JavaScript рендеринга)
* **OCR:** Tesseract-OCR с поддержкой русского и английского языков
* **Документооборот:** LibreOffice (headless режим)
* **Контейнеризация:** Docker с многоэтапной сборкой

### 7. Управление проектом и тестирование

**7.1. Makefile**
```makefile
# Makefile для управления жизненным циклом API
IMAGE_NAME := text-extraction-api
TAG := latest

.PHONY: help build dev prod stop logs test clean

help:
  @echo "Команды: build, dev, prod, stop, logs, test, clean"

build:
  docker build -t $(IMAGE_NAME):$(TAG) .

dev: build
  docker-compose -f docker-compose.yml up

prod: build
  docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d

stop:
  docker-compose -f docker-compose.yml -f docker-compose.prod.yml down

logs:
  docker-compose -f docker-compose.yml -f docker-compose.prod.yml logs -f

test:
  @echo "Запуск тестов конвертации..."
  @./run_tests.sh

clean:
  docker-compose -f docker-compose.yml -f docker-compose.prod.yml down --volumes --remove-orphans
```

**7.2. docker-compose.yml (для разработки)**
```yaml
version: '3.8'
services:
  api:
    image: text-extraction-api:latest
    build: .
    command: uvicorn app.main:app --host 0.0.0.0 --port ${API_PORT:-7555} --workers ${WORKERS:-1} --reload
    ports:
      - "${API_PORT:-7555}:${API_PORT:-7555}"
    volumes:
      - ./app:/code/app
      - ./tests:/code/tests
    env_file:
      - .env
```

**7.3. docker-compose.prod.yml (для продакшена)**
```yaml
version: '3.8'
services:
  api:
    volumes: []
    command: >
      sh -c "
        CALCULATED_WORKERS=$$(expr 2 \* $${CPU_CORES:-4} + 1);
        exec uvicorn app.main:app --host 0.0.0.0 --port $${API_PORT:-7555} --workers $${WORKERS:-$$CALCULATED_WORKERS}
      "
    restart: always
    env_file:
      - .env
```

**7.4. Тестирование (`make test`)**

**7.4.1. Фреймворк тестирования**
* **Основной фреймворк:** pytest + pytest-asyncio для тестирования асинхронного кода FastAPI
* **Покрытие кода:** pytest-cov для измерения покрытия с минимальным порогом 60%
* **HTTP клиент:** httpx для тестирования API эндпоинтов (официально рекомендуется для FastAPI)
* **Моки и фикстуры:** pytest-mock для создания заглушек внешних зависимостей

**7.4.2. Структура тестов**
```
tests/
├── conftest.py          # Общие фикстуры и настройки
├── test_main.py         # Integration тесты API эндпоинтов
├── test_extractors.py   # Unit тесты логики извлечения текста
├── test_utils.py        # Unit тесты утилитарных функций
├── test_config.py       # Unit тесты конфигурации
├── test_integration.py  # Integration тесты с реальными файлами
└── pytest.ini          # Конфигурация pytest
```

**7.4.3. Типы тестов**
* **Unit тесты** (`make test-unit`): тестирование отдельных функций и методов в изоляции
* **Integration тесты** (`make test-integration`): тестирование взаимодействия компонентов и API эндпоинтов
* **Тесты с реальными файлами**: использование файлов из папки `tests/` для проверки функциональности
* **Тесты производительности**: проверка времени ответа и обработки одновременных запросов

**7.4.4. Покрытие кода**
* **Минимальный порог покрытия:** 60%
* **Отчеты покрытия:**
  - Терминальный отчет с указанием непокрытых строк
  - HTML отчет в папке `coverage_html/`
  - XML отчет для CI/CD систем
* **Команда просмотра:** `make test-coverage` для открытия HTML отчета в браузере

**7.4.5. Команды тестирования**
* `make test` - полное тестирование с покрытием кода
* `make test-unit` - только unit тесты
* `make test-integration` - только integration тесты
* `make test-coverage` - просмотр отчета покрытия
* `make test-legacy` - legacy функциональные тесты через `run_tests.sh`

**7.4.6. Legacy функциональное тестирование (`make test-legacy`)**
* В корне проекта сохранен скрипт `run_tests.sh` для итерации по файлам в папке `tests` и проверки их конвертации через запущенный в Docker сервис.
* **Перед началом тестирования** скрипт удаляет все предыдущие результаты тестов (файлы `tests/*.ok.txt` и `tests/*.err.txt`) для обеспечения "чистого" запуска.
* Если файл успешно преобразован, создается файл `ИМЯ_ФАЙЛА.ok.txt` с извлеченным текстом.
* Если произошла ошибка, создается файл `ИМЯ_ФАЙЛА.err.txt` с текстом ошибки.
* Скрипт игнорирует служебные файлы (например, `supported_formats.json`, `*.ok.txt`, `*.err.txt`) при поиске файлов для тестирования.

**7.5. Проверка качества кода и CI/CD (`make lint`)**

**7.5.1. Инструменты проверки кода**
* **Форматирование кода:**
  - `black` - автоформатирование Python кода в соответствии с PEP 8
  - `isort` - сортировка и организация импортов
* **Проверка стиля:**
  - `flake8` - проверка соответствия PEP 8 и поиск ошибок кода
  - `mypy` - статическая проверка типов (опционально, не блокирует CI)
* **Безопасность:**
  - `bandit` - поиск уязвимостей в коде Python
  - `safety` - проверка зависимостей на известные уязвимости

**7.5.2. Конфигурационные файлы**
```
├── pyproject.toml       # Конфигурация black, isort, mypy, pytest
├── .flake8            # Настройки Flake8
└── requirements-lint.txt # Зависимости для проверки кода
```

**7.5.3. Команды проверки кода**
* `make install-linters` - установка инструментов для проверки кода
* `make format` - автоформатирование кода (black + isort)
* `make lint` - проверка кода всеми линтерами с выводом предупреждений
* `make lint-check` - строгая проверка без автоисправлений (для CI)

**7.5.4. GitHub Actions CI/CD Pipeline**

Проект включает автоматизированный pipeline (`github/workflows/ci.yml`) с следующими этапами:

**Этап 1: Проверка кода (Linting)**
- Проверка форматирования с Black
- Проверка стиля кода с Flake8  
- Проверка сортировки импортов с isort
- Проверка типов с MyPy (не блокирует при ошибках)

**Этап 2: Тестирование в Docker**
- Сборка Docker образа
- Запуск полного тестирования через `make test-docker`
- Генерация отчетов покрытия (XML, HTML)
- Загрузка покрытия в Codecov

**Этап 3: Матричное тестирование**
- Тестирование на Python 3.10, 3.11, 3.12
- Установка системных зависимостей (tesseract, libreoffice)
- Параллельные отчеты покрытия для каждой версии

**Этап 4: Проверка безопасности**
- Проверка кода с Bandit
- Проверка зависимостей с Safety
- Сохранение отчетов безопасности как артефактов

**Этап 5: Проверка сборки**
- Сборка и тестирование Docker образа
- Проверка health check эндпоинтов
- Функциональное тестирование API

**7.5.5. Артефакты и отчеты**
- **Отчеты покрытия:** сохраняются на 30 дней в GitHub Actions
- **Отчеты безопасности:** JSON файлы с результатами Bandit и Safety
- **Интеграция с Codecov:** автоматическая загрузка метрик покрытия
- **Бейджи статуса:** отображение состояния CI/CD в README

**7.6. Файл `.gitignore`**
В `.gitignore` должны быть добавлены результаты тестов и линтеров:
```gitignore
# Результаты тестов
tests/*.ok.txt
tests/*.err.txt

# Линтеры и инструменты проверки кода
.flake8-cache/
.bandit/
bandit-report.json
safety-report.json
```

### 8. Принципы разработки и лучшие практики

#### 8.1. Управление ресурсами
* **Принцип "ничего не должно утекать":** Любые ресурсы (файлы, соединения, память) должны быть явно освобождены, даже при возникновении исключений
* **Гарантированная очистка:** Используйте контекстные менеджеры и блоки `finally` для критически важных операций освобождения ресурсов
* **Профилактическая очистка:** Регулярно очищайте накопившиеся временные файлы при старте приложения

#### 8.2. Безопасность
* **Fail-closed по умолчанию:** При любых сомнительных ситуациях (ошибки валидации, неопределенные типы файлов) отклоняйте запрос
* **Контролируемая среда:** Изолируйте выполнение в контейнерах, используйте непривилегированных пользователей
* **Мониторинг состояния:** Обеспечьте возможность автоматической проверки работоспособности через healthcheck
* **Контекстная безопасность:** Учитывайте среду развертывания при настройке политик безопасности (CORS, аутентификация). Для корпоративных сетей допустимы более открытые политики при обеспечении сетевой безопасности

#### 8.3. Надежность инфраструктуры
* **Оптимизированные образы:** Используйте многоэтапную сборку для уменьшения размера и устранения уязвимостей
* **Автоматический мониторинг:** Интегрируйте healthcheck для работы с системами оркестрации
* **Версионирование:** Поддерживайте актуальную документацию изменений в CHANGELOG.md

#### 8.4. Принципы отказоустойчивости
* **Изоляция операций:** Ошибка в обработке одного файла не должна влиять на другие
* **Таймауты и лимиты:** Устанавливайте разумные ограничения на время и размер обработки
* **Детальное логирование:** Логируйте все критические операции с достаточной детализацией для диагностики

---

**Примечание:** Данные рекомендации основаны на критических исправлениях версии 1.8.3 и должны соблюдаться при любых дальнейших изменениях в проекте для обеспечения стабильности, безопасности и производительности системы.
